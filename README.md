# Learning Repository ğŸš€

> **My journey to master Deep Learning, LLMs, and Diffusion Models**

[![GitHub](https://img.shields.io/badge/GitHub-Hemraj183-blue?logo=github)](https://github.com/Hemraj183)
[![Learning](https://img.shields.io/badge/Status-Active%20Learning-green.svg)]()

## ğŸ¯ Learning Goals

This repository documents my journey to become proficient in modern AI/ML technologies with the ultimate goal of **creating new models from scratch**.

### Primary Objectives

1. âœ… **Deep Learning Fundamentals** - Master PyTorch and neural network basics
2. ğŸ¯ **Large Language Models (LLMs)** - Understand transformer architecture and build LLMs from scratch
3. ğŸ¯ **Diffusion Models** - Learn generative AI and create custom diffusion models
4. ğŸ¯ **Model Creation** - Develop the skills to design and implement novel architectures

## ğŸ“š Learning Path

### Phase 1: Deep Learning & PyTorch Fundamentals âœ…
**Status**: Completed  
**Location**: [`pytorch-tutorial/`](./pytorch-tutorial)

**What I Learned:**
- Autograd and automatic differentiation
- Custom nn.Modules with nn.Parameter
- GPU tensor handling
- Backpropagation and optimizers (AdamW)
- Built an MLP from scratch for MNIST (97-98% accuracy)

**Key Achievement**: Can write PyTorch training loops without documentation

---

### Phase 2: Large Language Models (LLMs) ğŸ¯
**Status**: Planned  
**Location**: `llm-foundations/` (coming soon)

**Learning Objectives:**
- Transformer architecture deep dive
- Attention mechanisms (self-attention, multi-head attention)
- Positional encodings
- Tokenization and embeddings
- Training techniques (teacher forcing, beam search)
- Fine-tuning and transfer learning
- Building a GPT-style model from scratch

**Planned Projects:**
- Implement transformer from scratch
- Build a character-level language model
- Create a small-scale GPT model
- Fine-tune pre-trained models

---

### Phase 3: Diffusion Models ğŸ¯
**Status**: Planned  
**Location**: `diffusion-models/` (coming soon)

**Learning Objectives:**
- Diffusion process (forward and reverse)
- Denoising techniques
- U-Net architecture
- Noise scheduling
- Conditional generation
- Latent diffusion models
- Building a diffusion model from scratch

**Planned Projects:**
- Implement DDPM (Denoising Diffusion Probabilistic Models)
- Create a simple image generator
- Build a conditional diffusion model
- Experiment with latent diffusion

---

### Phase 4: Advanced Topics & Model Creation ğŸ¯
**Status**: Future  
**Location**: `custom-models/` (coming soon)

**Learning Objectives:**
- Novel architecture design
- Hybrid models (combining transformers + diffusion)
- Efficient training techniques
- Model optimization and deployment
- Research paper implementation

## ğŸ“‚ Repository Structure

```
Learning/
â”œâ”€â”€ pytorch-tutorial/          # âœ… Phase 1: PyTorch Fundamentals
â”‚   â”œâ”€â”€ index.html            # Interactive tutorial
â”‚   â”œâ”€â”€ style.css             # Premium UI design
â”‚   â”œâ”€â”€ script.js             # Interactive features
â”‚   â””â”€â”€ README.md             # Project documentation
â”‚
â”œâ”€â”€ llm-foundations/          # ğŸ¯ Phase 2: LLM Learning (Coming Soon)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ diffusion-models/         # ğŸ¯ Phase 3: Diffusion Models (Coming Soon)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ custom-models/            # ğŸ¯ Phase 4: Novel Architectures (Coming Soon)
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md                 # This file
```

## ğŸ› ï¸ Technologies & Tools

- **Deep Learning**: PyTorch, TorchVision
- **LLMs**: Transformers, Hugging Face, Tokenizers
- **Diffusion**: Diffusers, Stable Diffusion
- **Development**: Python, Jupyter Notebooks, Git
- **Visualization**: Matplotlib, TensorBoard
- **Deployment**: ONNX, TorchScript

## ğŸ“– Resources

### Books & Papers
- "Deep Learning" by Ian Goodfellow
- "Attention Is All You Need" (Transformer paper)
- "Denoising Diffusion Probabilistic Models" (DDPM paper)
- "Language Models are Few-Shot Learners" (GPT-3 paper)

### Online Courses
- PyTorch Official Tutorials
- Hugging Face NLP Course
- Fast.ai Deep Learning Course
- Stanford CS224N (NLP with Deep Learning)

### Communities
- PyTorch Forums
- Hugging Face Community
- r/MachineLearning
- Papers With Code

## ğŸ“ Progress Tracking

| Phase | Topic | Status | Completion |
|-------|-------|--------|------------|
| 1 | PyTorch Fundamentals | âœ… Complete | 100% |
| 1 | MLP from Scratch | âœ… Complete | 100% |
| 2 | Transformer Architecture | ğŸ¯ Planned | 0% |
| 2 | GPT Implementation | ğŸ¯ Planned | 0% |
| 3 | Diffusion Basics | ğŸ¯ Planned | 0% |
| 3 | DDPM Implementation | ğŸ¯ Planned | 0% |
| 4 | Custom Model Design | ğŸ¯ Future | 0% |

## ğŸ’¡ Learning Principles

1. **Learn by Doing**: Implement everything from scratch before using libraries
2. **Understand the Math**: Don't just copy code, understand the theory
3. **Document Everything**: Write clear explanations and tutorials
4. **Build Projects**: Apply knowledge to real-world problems
5. **Share Knowledge**: Create tutorials and help others learn

## ğŸš€ Current Focus

**Now Learning**: Large Language Models (LLMs)
- Reading: "Attention Is All You Need" paper
- Implementing: Transformer architecture from scratch
- Goal: Build a working GPT-style model

## ğŸ“ Notes & Reflections

### PyTorch Fundamentals (Completed)
- **Key Insight**: Understanding autograd is crucial for debugging
- **Challenge**: Getting GPU memory management right
- **Achievement**: Built MLP without nn.Linear, achieved 97% accuracy on MNIST
- **Next**: Apply these fundamentals to more complex architectures

## ğŸ¤ Contributing

This is a personal learning repository, but suggestions and feedback are welcome! Feel free to:
- Suggest learning resources
- Point out errors or improvements
- Share your own learning experiences

## ğŸ“§ Contact

- **GitHub**: [@Hemraj183](https://github.com/Hemraj183)
- **Repository**: [Learning](https://github.com/Hemraj183/Learning)

## ğŸ“œ License

This repository is for educational purposes. Code and tutorials are free to use and learn from.

---

**Last Updated**: January 1, 2026  
**Current Phase**: Transitioning from PyTorch Fundamentals to LLM Foundations

> "The journey of a thousand miles begins with a single step." - Lao Tzu

**Let's build something amazing! ğŸš€**
