<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 3: LLM Variants & Tokenization | Deep Learning Mastery</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Global Progress Tracker (Hidden Metadata) -->
    <div id="course-metadata" data-current-week="week3_llm_variants" style="display:none;"></div>

    <!-- Sidebar -->
    <nav class="sidebar">
        <div class="sidebar-header">
            <h2>LLMs & GPT-2</h2>
            <div class="progress-container">
                 <div class="progress-bar"><div class="progress-fill" id="page-progress"></div></div>
                 <span class="progress-text" id="progress-text">0% Complete</span>
            </div>
            <a href="../../index.html" class="back-link">‚Üê Course Dashboard</a>
        </div>
        
        <div class="nav-scroll-area">
            <h3 class="nav-section-title">This Module</h3>
            <ul class="nav-links local-nav">
                <li><a href="#intro">üìñ Introduction</a></li>
                <li><a href="#theory">üß† Theory & Math</a></li>
                <li><a href="#interactive">üî¨ Interactive Lab</a></li>
                <li><a href="#code">üíª Implementation</a></li>
                <li><a href="#project">üéØ Project</a></li>
            </ul>

            <h3 class="nav-section-title" style="margin-top:20px;">Course Map</h3>
            <ul class="nav-links global-nav">
                <li><a href="../week1_pytorch/index.html" class="week-link" data-week="week1_pytorch">Week 1: PyTorch</a></li>
                <li><a href="../week2_transformer/index.html" class="week-link" data-week="week2_transformer">Week 2: Transformers</a></li>
                <li><a href="../week3_llm_variants/index.html" class="week-link" data-week="week3_llm_variants">Week 3: LLMs</a></li>
                <li><a href="../week4_router/index.html" class="week-link" data-week="week4_router">Week 4: Router</a></li>
                <li><a href="../week5_diffusion/index.html" class="week-link" data-week="week5_diffusion">Week 5: Diffusion</a></li>
                <li><a href="../week6_unet/index.html" class="week-link" data-week="week6_unet">Week 6: U-Net</a></li>
                <li><a href="../week7_ldm/index.html" class="week-link" data-week="week7_ldm">Week 7: Latent Diff.</a></li>
                <li><a href="../week8_capstone/index.html" class="week-link" data-week="week8_capstone">Week 8: Capstone</a></li>
                <li><a href="../week9_lora/index.html" class="week-link" data-week="week9_lora">Week 9: LoRA</a></li>
                <li><a href="../week10_moe/index.html" class="week-link" data-week="week10_moe">Week 10: MoE</a></li>
                <li><a href="../week11_opt/index.html" class="week-link" data-week="week11_opt">Week 11: Opt</a></li>
                <li><a href="../week12_capstone/index.html" class="week-link" data-week="week12_capstone">Week 12: Final</a></li>
            </ul>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="content">
        <!-- Hero -->
        <section id="intro" class="hero-section">
            <h1 class="gradient-text">Week 3: LLM Variants & Tokenization</h1>
            <p class="subtitle">Understanding the data pipeline and architectures of GPT-2, LLaMA, and more.</p>
            <div class="content-card">
                <h3>Overview</h3>
                <p>Large Language Models are not just "big transformers". They rely on sophisticated tokenization, positional embeddings (RoPE, ALiBi), and decoding strategies. This week focues on the <strong>input pipeline</strong> and the <strong>decoder-only</strong> architecture typical of GPT models.</p>
                <div class="checkpoint">
                    <input type="checkbox" id="check-intro" class="checkpoint-input" onchange="updateProgress()">
                    <label for="check-intro">I understand the goals of this week</label>
                </div>
            </div>
        </section>

        <!-- Theory -->
        <section id="theory" class="section">
            <h2 class="section-title">Theory & Concepts</h2>
            
        <div class="content-card">
            <h3>Byte-Pair Encoding (BPE)</h3>
            <p>Computers don't read words. They deal with numbers. Simple character-level selection is too verbose, and word-level is too sparse.</p>
            <p><strong>BPE</strong> starts with characters and iteratively merges the most frequent pairs. <code>('u', 'n') -> 'un'</code>. Eventually <code>('un', 'related') -> 'unrelated'</code>.</p>
        </div>
        <div class="content-card">
            <h3>Decoder-Only Architecture (GPT)</h3>
            <p>Unlike BERT (Encoder), GPT is a specific type of Transformer that uses <strong>Masked Self-Attention</strong>. It cannot look at future tokens.</p>
            <div class="code-block">mask = torch.tril(torch.ones(seq_len, seq_len))</div>
        </div>
        
             <div class="content-card">
                 <h3>Concept Check</h3>
                 <p>Make sure you grasp the core equations before moving to code.</p>
                 <div class="checkpoint">
                    <input type="checkbox" id="check-theory" class="checkpoint-input" onchange="updateProgress()">
                    <label for="check-theory">I have reviewed the theoretical foundations</label>
                </div>
             </div>
        </section>

        <!-- Interactive -->
        <section id="interactive" class="section">
            <h2 class="section-title">Interactive Lab: Visual Tokenizer</h2>
            <div class="content-card viz-card">
                <p>See how text gets chopped into tokens. Notice how common words are single tokens, while rare words are split.</p>
                <div class="viz-container" id="viz-container">
                    <input type="text" id="t-in" placeholder="Type text..." onkeyup="tokenize()" style="width:100%; padding:10px;"><div id="t-out" style="display:flex; flex-wrap:wrap; gap:5px; margin-top:20px;"></div>
                </div>
                <div class="info-box"><strong>üí° Experiment:</strong> Try different values to see how the system reacts in real-time.</div>
            </div>
        </section>

        <!-- Implementation -->
        <section id="code" class="section">
            <h2 class="section-title">Code Implementation</h2>
            <div class="content-card">
                <h3>Core Logic</h3>
                <p>Below is the critical implementation from <code>project.py</code>. Analyze how the theory transforms into PyTorch code.</p>
                <div class="code-block">
                    <div class="code-header">Python <button class="copy-btn" onclick="copyCode()">Copy</button></div>
                    <pre><code id="main-code"># Generating text with a causal mask
def generate(model, context, max_new_tokens):
    for _ in range(max_new_tokens):
        # Crop context to context_window
        context_cond = context[:, -block_size:]
        
        # Get predictions
        logits, _ = model(context_cond)
        
        # Focus only on the last time step
        logits = logits[:, -1, :]
        
        # Apply softmax to get probabilities
        probs = F.softmax(logits, dim=-1)
        
        # Sample from the distribution
        idx_next = torch.multinomial(probs, num_samples=1)
        
        # Append to running sequence
        context = torch.cat((context, idx_next), dim=1)
    return context</code></pre>
                </div>
                 <div class="checkpoint">
                    <input type="checkbox" id="check-code" class="checkpoint-input" onchange="updateProgress()">
                    <label for="check-code">I understand the code implementation</label>
                </div>
            </div>
        </section>
        
        <!-- Project -->
        <section id="project" class="section">
             <h2 class="section-title">Weekly Project</h2>
             <div class="content-card">
                <h3>Mini-GPT</h3>
                <p>Load GPT-2 weights and implement a text generation loop with Temperature and Top-K sampling.</p>
                <div class="project-specs">
                    <h4>Step-by-Step Implementation</h4>
                    <ul class="checklist">
                        
            <li>Load <code>gpt2</code> using HuggingFace Transformers.</li>
            <li>Explore the <code>vocab.json</code> to understand BPE.</li>
            <li>Implement the <code>generate()</code> function manually (no <code>model.generate</code>).</li>
            <li>Add <strong>Temperature</strong> scaling to control randomness.</li>
        
                    </ul>
                </div>
                <div class="info-box">
                    <strong>üöÄ Challenge:</strong> Can you optimize this further? Check the <code>exercises.py</code> file for bonus tasks.
                </div>
                 <div class="checkpoint">
                    <input type="checkbox" id="check-project" class="checkpoint-input" onchange="updateProgress()">
                    <label for="check-project">I have completed the weekly project</label>
                </div>
             </div>
        </section>

        <footer>
            <div class="nav-buttons">
                <a href="../../modules/week2_transformer/index.html" class="btn-secondary">‚Üê Previous Week</a>
                <a href="../../modules/week4_router/index.html" class="btn-primary">Next Week ‚Üí</a>
            </div>
            <p style="margin-top: 40px; color: var(--text-muted);">Antigravity Learning System &copy; 2026</p>
        </footer>
    </main>

    <script src="script.js"></script>
    <script>
        // Global Progress Logic
        const CURRENT_WEEK = "week3_llm_variants";
        
        function updateProgress() {
            const checks = document.querySelectorAll('.checkpoint-input');
            const checked = document.querySelectorAll('.checkpoint-input:checked');
            const progress = (checked.length / checks.length) * 100;
            
            document.getElementById('page-progress').style.width = `${progress}%`;
            document.getElementById('progress-text').innerText = `${Math.round(progress)}% Complete`;
            
            // Save to localStorage
            const state = {};
            checks.forEach(c => state[c.id] = c.checked);
            localStorage.setItem(`progress_${CURRENT_WEEK}`, JSON.stringify(state));
            
            // Mark week as done if > 90%
            if (progress > 90) {
                localStorage.setItem(`status_${CURRENT_WEEK}`, 'done');
            }
        }

        function loadProgress() {
             const saved = JSON.parse(localStorage.getItem(`progress_${CURRENT_WEEK}`));
             if (saved) {
                 Object.keys(saved).forEach(id => {
                     const el = document.getElementById(id);
                     if(el) el.checked = saved[id];
                 });
                 updateProgress();
             }
             
             // Update sidebar ticks
             document.querySelectorAll('.week-link').forEach(link => {
                 const week = link.getAttribute('data-week');
                 if (localStorage.getItem(`status_${week}`) === 'done') {
                     link.classList.add('done-week');
                 }
                 if (week === CURRENT_WEEK) link.classList.add('active-week');
             });
        }
        
        function copyCode() {
            const code = document.getElementById('main-code').innerText;
            navigator.clipboard.writeText(code);
            alert('Code copied!');
        }

        window.onload = loadProgress;
    </script>
</body>
</html>
